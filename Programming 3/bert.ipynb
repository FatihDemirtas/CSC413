{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63a1ecd42f924e9f924ee81a4704ef8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ba54ea111ed447eb2bfeaf4e8d1d6aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88d9ee1b137842afb7df4fb6c501069f",
              "IPY_MODEL_45450ce085cd4b47a1431ee2b4eda42c"
            ]
          }
        },
        "6ba54ea111ed447eb2bfeaf4e8d1d6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88d9ee1b137842afb7df4fb6c501069f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_462c495656384a05bacc2fd3c1607b3a",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccd4bb6c815848749e39f0b204c33fa0"
          }
        },
        "45450ce085cd4b47a1431ee2b4eda42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3846a322a55a44d383b242c35f12827f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 416kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71d24c72cadd4e03acb9543a78c95976"
          }
        },
        "462c495656384a05bacc2fd3c1607b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccd4bb6c815848749e39f0b204c33fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3846a322a55a44d383b242c35f12827f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71d24c72cadd4e03acb9543a78c95976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7d8cc2d19dc4af6951c187e145096c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6eb8735e4fbe46ab831e6929b73f5726",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26bc2ba06ecb4bf3aae083b350b56c83",
              "IPY_MODEL_654bd94e4cb740f683da2b30ee372875"
            ]
          }
        },
        "6eb8735e4fbe46ab831e6929b73f5726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26bc2ba06ecb4bf3aae083b350b56c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b7c5c21770844a9921e523aa8abcb2e",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0d9674f22c941d6a73678678c7e8823"
          }
        },
        "654bd94e4cb740f683da2b30ee372875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7896c187f2744069f529d2da89d15bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 14.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11ca2ef3c5ff4514886bf01b3b2102a6"
          }
        },
        "4b7c5c21770844a9921e523aa8abcb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0d9674f22c941d6a73678678c7e8823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7896c187f2744069f529d2da89d15bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11ca2ef3c5ff4514886bf01b3b2102a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24c4e5cdf38f4f7f890dab0254e90b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1604b3651ae1495797ac7ec307fd8ed4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_716cb3a2beeb4591bf21e30910c0765e",
              "IPY_MODEL_fea80a09390741b9aa4cb0df320da245"
            ]
          }
        },
        "1604b3651ae1495797ac7ec307fd8ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "716cb3a2beeb4591bf21e30910c0765e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84217c8389e3452e8d8863e378f94300",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52b912362fc3413dba2cd2a9f66ab98d"
          }
        },
        "fea80a09390741b9aa4cb0df320da245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_59acb824265a480cb2815e2193dd60e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:40&lt;00:00, 10.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_617cd73c7d2c49a4b6c65aaf65843ecc"
          }
        },
        "84217c8389e3452e8d8863e378f94300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52b912362fc3413dba2cd2a9f66ab98d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59acb824265a480cb2815e2193dd60e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "617cd73c7d2c49a4b6c65aaf65843ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej",
        "colab_type": "text"
      },
      "source": [
        "#Part 4 BERT for arithmetic sentiment analysis\n",
        "\n",
        "Acknowledgement: We used most of the code from https://mccormickml.com/2019/07/22/BERT-fine-tuning/ \n",
        "\n",
        "Most Credit to: \n",
        "Chris McCormick and Nick Ryan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhPwblrwyDxj",
        "colab_type": "text"
      },
      "source": [
        "# Bert Background\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyytew4tyT8z",
        "colab_type": "text"
      },
      "source": [
        "**B**idirectional **E**ncoder **R**epresentations from\n",
        "**T**ransformers (BERT) [Devlin  et  al.,  2019], as the name suggests, is a language model based on the Transformer  [Vaswani et al., 2017] encoder architecture that has been pre-trained on a large dataset of unlabeled sentences from Wikipedia and BookCorpus [Zhu et al., 2015]. Given a sequence of tokens representing sentence(s), BERT outputs a ``contextualized representation\" vector for each of the token. Now, suppose we are given some down-stream tasks, such as sentence classification or question-answering. We can take the BERT model, add a small layer on top of the BERT representation(s), and then fine-tune the added parameters **and** BERT parameters on the down-stream dataset, which is typically much smaller than the data used to pre-train BERT. \n",
        "\n",
        "In traditional language modeling task, the objective is to maximize the log likelihood of predicting the current word (or token) in the sentence, given the previous words (to the left of current work) as context. This is called the *autoregressive model*. In BERT, however, we wish to predict the current word given both the words before and after (i.e. to the left and to the right) of the sentence--hence *bidirectional*.\n",
        "To be able to attend from both directions, BERT uses the encoder Transformer, which does not apply any attention masking unlike the decoder.\n",
        "\n",
        "We briefly describe how BERT is pre-trained. BERT has 2 task objectives for pre-training: (1) *Masked Language Modeling* (Masked LM), and (2) *Next Sentence Prediction*(NSP). The input to the model is a sequence of tokens of the form:\n",
        "```\n",
        "    [CLS] Sentence A [SEP] Sentence B,\n",
        "```\n",
        "where `[CLS]`  (\"class\") and `[SEP]` (\"separator\") are special tokens. \n",
        "In Masked LM, some percentage of the input tokens are converted into `[MASK]` tokens, and the objective is to use the final layer representation for that masked token to predict the correct word that was masked out. For NSP, the task is to use the contextualized representation for the `[CLS]` token to perform binary classification for whether sentence A and sentence B are consecutive sentences in the unlabeled dataset. See Figure 6 (in Handout) for the conceptual picture of BERT pre-training and fine-tuning. \n",
        "\n",
        "In this assignment, you will be **fine-tuning BERT on a single sentence classification task** (see below about the dataset). Figure 7 (in Handout) illustrates the architecture for fine-tuning on this task. We prepend the tokenized sentence with the `[CLS]` token, then feed the sequence into BERT. We then take the contextualized `[CLS]` token representation at the last layer of BERT and add either a softmax layer on top corresponding to the number of output classes in the task. Alternatively, we can have fully connected hidden layers before the softmax layer for more expressivity for harder tasks. Then, both the new layers and the entire BERT parameters are trained end to end on the task for a few epochs. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI",
        "colab_type": "text"
      },
      "source": [
        "## Install transformers repo that has Bert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab_type": "code",
        "outputId": "5c36f77a-0a37-4a39-9ba8-a322f49e0619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 41.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.18)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=6918dcbdc0df4b10a7d5e856efe5980869b02e61a60c8093b10bc1efecc5d9f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn",
        "colab_type": "text"
      },
      "source": [
        "## Download & Extract\n",
        "Run the following cells to downlaod the dataset files from the CSC413 webpage.\n",
        "\n",
        "<!-- Download the two csv dataset files from CSC413 webpage, click the folder icon,  -->\n",
        "<!-- and click \"upload\" to upload them.  -->\n",
        "\n",
        "<!-- https://csc413-2020.github.io/assets/misc/PA03_data_20_train.csv \n",
        "\n",
        "https://csc413-2020.github.io/assets/misc/PA03_data_20_test.csv   -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ydihgBb-AiY",
        "colab_type": "code",
        "outputId": "36272eb8-0e33-4264-8ad4-c67426c8f031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=6d4766d13516c4b502f3ddaf9d76ddb92b194169b95292d309002ea9e7f64d2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W9K3PG3-C5W",
        "colab_type": "code",
        "outputId": "a6f3e729-210a-4893-99eb-e4d69ce1bdd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading verbal arithmetic dataset')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://csc413-2020.github.io/assets/misc/'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./PA03_data_20_train.csv'):\n",
        "  wget.download(url + 'PA03_data_20_train.csv', './PA03_data_20_train.csv')\n",
        "  print('Done downloading training data')\n",
        "else:\n",
        "  print('Already downloaded training data')\n",
        "\n",
        "if not os.path.exists('./PA03_data_20_test.csv'):\n",
        "  wget.download(url + 'PA03_data_20_test.csv', './PA03_data_20_test.csv')\n",
        "  print('Done downloading test data')\n",
        "else:\n",
        "  print('Already downloaded test data')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading verbal arithmetic dataset\n",
            "Done downloading training data\n",
            "Done downloading test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##  Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab_type": "code",
        "outputId": "761eee6a-6f42-4c2c-c339-eeec172c65a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"./PA03_data_20_train.csv\", header=0, names=[\"index\", \"input\", \"label\"])\n",
        "\n",
        "print(\"Number of data points: \", df.shape[0])\n",
        "sampled = df.sample(10)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points:  640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>257</td>\n",
              "      <td>twelve plus seventeen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>112</td>\n",
              "      <td>five plus twelve</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>560</td>\n",
              "      <td>eight minus zero</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>258</td>\n",
              "      <td>twelve plus eighteen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>731</td>\n",
              "      <td>sixteen minus eleven</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>791</td>\n",
              "      <td>nineteen minus eleven</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>671</td>\n",
              "      <td>thirteen minus eleven</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>717</td>\n",
              "      <td>fifteen minus seventeen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>96</td>\n",
              "      <td>four plus sixteen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>494</td>\n",
              "      <td>four minus fourteen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                    input  label\n",
              "108    257    twelve plus seventeen      2\n",
              "488    112         five plus twelve      2\n",
              "214    560         eight minus zero      2\n",
              "610    258     twelve plus eighteen      2\n",
              "90     731     sixteen minus eleven      2\n",
              "39     791    nineteen minus eleven      2\n",
              "400    671    thirteen minus eleven      2\n",
              "527    717  fifteen minus seventeen      0\n",
              "421     96        four plus sixteen      2\n",
              "475    494      four minus fourteen      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh-kNWFRltMk",
        "colab_type": "code",
        "outputId": "34c26e26-2a02-4ae8-a3d9-3821fb036483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>512</td>\n",
              "      <td>five minus twelve</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>261</td>\n",
              "      <td>thirteen plus one</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>139</td>\n",
              "      <td>six plus nineteen</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>492</td>\n",
              "      <td>four minus twelve</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150</td>\n",
              "      <td>seven plus ten</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index              input  label\n",
              "0    512  five minus twelve      0\n",
              "1    261  thirteen plus one      2\n",
              "2    139  six plus nineteen      2\n",
              "3    492  four minus twelve      0\n",
              "4    150     seven plus ten      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWzpPi92UAH",
        "colab_type": "text"
      },
      "source": [
        "The two properties we actually care about are the the `inputs` and its `label`, which are the questions and the answers.  \n",
        "\n",
        "**label=0** means the result of expression is **negative**\n",
        "\n",
        "**label=1** means the result of expression is **zero**\n",
        "\n",
        "**label=2** means the result of expression is **positive** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5",
        "colab_type": "text"
      },
      "source": [
        "## BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab_type": "code",
        "outputId": "db2d3aa5-38ed-43b6-da44-47967a2bc8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128,
          "referenced_widgets": [
            "63a1ecd42f924e9f924ee81a4704ef8d",
            "6ba54ea111ed447eb2bfeaf4e8d1d6aa",
            "88d9ee1b137842afb7df4fb6c501069f",
            "45450ce085cd4b47a1431ee2b4eda42c",
            "462c495656384a05bacc2fd3c1607b3a",
            "ccd4bb6c815848749e39f0b204c33fa0",
            "3846a322a55a44d383b242c35f12827f",
            "71d24c72cadd4e03acb9543a78c95976"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a1ecd42f924e9f924ee81a4704ef8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab_type": "code",
        "outputId": "5d7fc32b-c44c-4241-bec7-4618d1060b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "inputs = df.input.values\n",
        "labels = df.label.values\n",
        "print(\"Train data size \", len(inputs))\n",
        "print(' Original: ', inputs[0])\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(inputs[0]))\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inputs[0])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data size  640\n",
            " Original:  five minus twelve\n",
            "Tokenized:  ['five', 'minus', 'twelve']\n",
            "Token IDs:  [2274, 15718, 4376]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNIc4auFUdF",
        "colab_type": "text"
      },
      "source": [
        "We can actually use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKGCCh8izww",
        "colab_type": "text"
      },
      "source": [
        "## BERT Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDcqNlvVhL5W",
        "colab_type": "text"
      },
      "source": [
        "In a deep learning based NLP pipeline, most of the following preprocessing tricks are frequently needed regardless of whether we use BERT or RNN.\n",
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6mceWWOjZnw",
        "colab_type": "text"
      },
      "source": [
        "### Special Tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykk0P9JiKtVe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**`[SEP]`**\n",
        "\n",
        "At the end of every sentence, we need to append the special `[SEP]` token. \n",
        "\n",
        "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86C9objaKu8f",
        "colab_type": "text"
      },
      "source": [
        "**`[CLS]`**\n",
        "\n",
        "For classification tasks, we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
        "\n",
        "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output.\n",
        "\n",
        "On the output of the final transformer, *only the first embedding (corresponding to the [CLS] token) is used by the classifier*.\n",
        "\n",
        ">  \"The first token of every sequence is always a special classification token (`[CLS]`). The final hidden state\n",
        "corresponding to this token is used as the aggregate sequence representation for classification\n",
        "tasks.\" (from the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n",
        "Also, because BERT is trained to only use this [CLS] token for classification, we know that the model has been motivated to encode everything it needs for the classification step into that single 768-value embedding vector.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u51v0kFxeteu",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Length & Attention Mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPNuwqZVK3T6",
        "colab_type": "text"
      },
      "source": [
        "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
        "\n",
        "BERT has two constraints:\n",
        "1. All sentences must be padded or truncated to a single, fixed length.\n",
        "2. The maximum sentence length is 512 tokens.\n",
        "\n",
        "Padding is done with a special `[PAD]` token, which is at index 0 in the BERT vocabulary. \n",
        "\n",
        "The \"Attention Mask\" is simply an array of 1s and 0s indicating which tokens are padding and which aren't \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ",
        "colab_type": "text"
      },
      "source": [
        "## Sentences to IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M296yz577fV",
        "colab_type": "text"
      },
      "source": [
        "The `tokenizer.encode` function combines multiple steps for us:\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "\n",
        "Oddly, this function can perform truncating for us, but doesn't handle padding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJBVKCyl0HZl",
        "colab_type": "code",
        "outputId": "305ac627-7709-43e3-f1d1-eb8d58eee3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# For Verbal Arithmetic\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for input in inputs:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_input = tokenizer.encode(\n",
        "                        input,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_input)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', inputs[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  five minus twelve\n",
            "Token IDs: [101, 2274, 15718, 4376, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhwCKszh6ych",
        "colab_type": "text"
      },
      "source": [
        "## Padding & Truncating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0",
        "colab_type": "text"
      },
      "source": [
        "Pad and truncate our sequences so that they all have the same length, `MAX_LEN`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqiWTDrn_nGB",
        "colab_type": "text"
      },
      "source": [
        "First, what's the maximum sentence length in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhUZO9vc_l6T",
        "colab_type": "code",
        "outputId": "16030601-f303-437f-ea4b-47e1ff563d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp-54FcQ_p3h",
        "colab_type": "text"
      },
      "source": [
        "Given that, let's choose MAX_LEN = 7 since our numerical expression is quite short. Then apply the padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp9BPRd1tMIo",
        "colab_type": "code",
        "outputId": "f61c73da-a6fc-4681-e32b-27ffbd9690ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "MAX_LEN = 7\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 7 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDs-MYtYH8sL",
        "colab_type": "text"
      },
      "source": [
        "## Attention Masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT",
        "colab_type": "text"
      },
      "source": [
        "The attention mask simply makes it explicit which tokens are actual words versus which are padding. \n",
        "\n",
        "The BERT vocabulary does not use the ID 0, so if a token ID is 0, then it's padding, and otherwise it's a real token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoC24LeEv3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_",
        "colab_type": "text"
      },
      "source": [
        "## Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06",
        "colab_type": "text"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbE-UHvsb7-",
        "colab_type": "code",
        "outputId": "666bdb9b-a5b5-4b30-d570-b63031b4aa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "print(input_ids)\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "set(labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  101  2274 15718 ...   102     0     0]\n",
            " [  101  7093  4606 ...   102     0     0]\n",
            " [  101  2416  4606 ...   102     0     0]\n",
            " ...\n",
            " [  101  2809  4606 ...   102     0     0]\n",
            " [  101  2698 15718 ...   102     0     0]\n",
            " [  101  2176  4606 ...   102     0     0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LzSbTqW9_BR",
        "colab_type": "text"
      },
      "source": [
        "## Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p1uXczp-Je4",
        "colab_type": "text"
      },
      "source": [
        "Our model expects PyTorch tensors rather than numpy.ndarrays, so convert all of our dataset variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5K2A5Ko1RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqCrZsMelOQz",
        "colab_type": "code",
        "outputId": "83a40954-288e-4ff6-aad4-94980e5482f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(torch.cuda.get_device_name())\n",
        "print(train_inputs.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_masks.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla K80\n",
            "torch.Size([576, 7])\n",
            "torch.Size([576])\n",
            "torch.Size([576, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN",
        "colab_type": "text"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-",
        "colab_type": "text"
      },
      "source": [
        "# 4. Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y_wqqvFhu1dQ"
      },
      "source": [
        "## Question1 [0pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwE1YaCY94Ra",
        "colab_type": "text"
      },
      "source": [
        "The pre-trained neural network here is the normal BERT model from [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). The goal is to add a new classification layer to the pre-trained model. We have provided two example classes to do so.\n",
        "\n",
        "In this part, you need to make your own  `BertCSC413_MLP` class `self.classifier` by, for example, modifying the provided examples: change the number of layers; change the number of hidden neurons; or try a different activation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJKHoftQ_Wsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "import torch.nn as nn\n",
        "class BertCSC413_Linear(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super(BertCSC413_Linear, self).__init__(config)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "\n",
        "class BertCSC413_MLP_Example(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super(BertCSC413_MLP_Example, self).__init__(config)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, config.hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "            )\n",
        "\n",
        "class BertCSC413_MLP(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super(BertCSC413_MLP, self).__init__(config)\n",
        "        # Your own classifier goes here\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, 512), # hidden_size = 768\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(512, self.config.num_labels)\n",
        "        )\n",
        "        #TODO Try more layers or different activations "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc",
        "colab_type": "text"
      },
      "source": [
        "## Question2 [0pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2C--cnF_TlD",
        "colab_type": "text"
      },
      "source": [
        "We instantiated two different BERT models from `BertCSC413_MLP` class, which are called `model_freeze_bert` and `model_finetune_bert` in the notebook. \n",
        "\n",
        "**Run** the following code to train the models, and attach the training error curves of `model_freeze_bert` and `model_finetune_bert`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab_type": "code",
        "outputId": "9ab6be51-bf3f-4607-b4b5-ea88b5165e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "e7d8cc2d19dc4af6951c187e145096c5",
            "6eb8735e4fbe46ab831e6929b73f5726",
            "26bc2ba06ecb4bf3aae083b350b56c83",
            "654bd94e4cb740f683da2b30ee372875",
            "4b7c5c21770844a9921e523aa8abcb2e",
            "c0d9674f22c941d6a73678678c7e8823",
            "f7896c187f2744069f529d2da89d15bf",
            "11ca2ef3c5ff4514886bf01b3b2102a6",
            "24c4e5cdf38f4f7f890dab0254e90b05",
            "1604b3651ae1495797ac7ec307fd8ed4",
            "716cb3a2beeb4591bf21e30910c0765e",
            "fea80a09390741b9aa4cb0df320da245",
            "84217c8389e3452e8d8863e378f94300",
            "52b912362fc3413dba2cd2a9f66ab98d",
            "59acb824265a480cb2815e2193dd60e5",
            "617cd73c7d2c49a4b6c65aaf65843ecc"
          ]
        }
      },
      "source": [
        "from transformers import AdamW, BertConfig\n",
        "\n",
        "model_freeze_bert = BertCSC413_MLP.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 3, \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False,\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7d8cc2d19dc4af6951c187e145096c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24c4e5cdf38f4f7f890dab0254e90b05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCrbP2RUjmXO",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "for name, param in model_freeze_bert.named_parameters():\n",
        "\tif 'classifier' not in name: # classifier layer\n",
        "\t\tparam.requires_grad = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8UyhbERf0W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_finetune_bert = BertCSC413_MLP.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 3,    \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab_type": "code",
        "outputId": "a0cf08e6-b63d-467c-8ced-3afd79f5d0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "# Model parameters visualization\n",
        "params = list(model_finetune_bert.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 203 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.0.weight                                       (512, 768)\n",
            "classifier.0.bias                                             (512,)\n",
            "classifier.2.weight                                         (3, 512)\n",
            "classifier.2.bias                                               (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk",
        "colab_type": "text"
      },
      "source": [
        "We use\n",
        "- Batch size: 32\n",
        "- Learning rate (Adam): 2e-5  \n",
        "- Number of epochs: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBhTDu3jqgeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    lr: float=2e-5,\n",
        "    epochs: int=4\n",
        "):      \n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                  lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)\n",
        "    loss_values = []\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "        t0 = time.time()\n",
        "\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            b_input_ids = batch[0] #.to(device)\n",
        "            b_input_mask = batch[1] #.to(device)\n",
        "            b_labels = batch[2] #.to(device)\n",
        "\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # This will return the loss (rather than the model output) because we\n",
        "            # have provided the `labels`.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "            \n",
        "            # The call to `model` always returns a tuple, so we need to pull the \n",
        "            # loss value out of the tuple.\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_train_loss = total_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Store the loss value for plotting the learning curve.\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "            \n",
        "\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "        model.eval()\n",
        "\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            # batch = tuple(t.to(device) for t in batch)\n",
        "            batch = tuple(t for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            \n",
        "            with torch.no_grad():        \n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # This will return the logits rather than the loss because we have\n",
        "                # not provided labels.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask)\n",
        "            \n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            logits = outputs[0]\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            # Calculate the accuracy for this batch of test sentences.\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "            # Accumulate the total accuracy.\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            # Track the number of batches\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "    return loss_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwm_4q5LuHAC",
        "colab_type": "code",
        "outputId": "51d33c5a-3bd9-4c81-9951-6d69f6691b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "freeze_bert_loss_vals = train_model(model_freeze_bert) # about 1 minute for 4 epochs using CPU"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.91\n",
            "  Training epcoh took: 0:00:14\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.79\n",
            "  Training epcoh took: 0:00:14\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.75\n",
            "  Training epcoh took: 0:00:13\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.73\n",
            "  Training epcoh took: 0:00:13\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX8jzBSluAtA",
        "colab_type": "code",
        "outputId": "4a78a300-b0ee-400c-e90d-3dfd9111aeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "finttune_bert_loss_vals = train_model(model_finetune_bert) # about 5 minutes for 4 epochs using CPU"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.99\n",
            "  Training epcoh took: 0:01:24\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.72\n",
            "  Training epcoh took: 0:01:24\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:01:25\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:01:24\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab_type": "code",
        "outputId": "dd64f3f7-e6e9-4e5c-d7a7-dbb8b668393a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "def plot_loss_vals(loss_vals):\n",
        "    sns.set(style='darkgrid')\n",
        "    sns.set(font_scale=1.5)\n",
        "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "    plt.plot(loss_vals, 'b-o')\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "plot_loss_vals(freeze_bert_loss_vals)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvoAAAGaCAYAAAB+A+cSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_7H1trGWQ0R",
        "colab_type": "code",
        "outputId": "6d81c25c-12ef-4261-c8e1-d2f62ac56afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "plot_loss_vals(finttune_bert_loss_vals)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQxYYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naNxk-y6Bn1F",
        "colab_type": "text"
      },
      "source": [
        "*Run* the evaluation functions.  Report the test performances of using trained model\\_freeze\\_bert and model\\_finetune\\_bert, and briefly discuss why models are failing under certain target labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab_type": "code",
        "outputId": "e50847c8-6218-4568-f444-719b6e71e606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "#df = pd.read_csv(\"./output.txt_test.csv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df = pd.read_csv(\"./PA03_data_20_test.csv\", header=0, names=[\"index\", \"input\", \"label\"])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "inputs = df.input.values\n",
        "labels = df.label.values\n",
        "\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "input_sent = []\n",
        "\n",
        "# For every sentence...\n",
        "for arithmetic_input in inputs:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        arithmetic_input, \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    input_sent.append(arithmetic_input)\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_testdata(model_test, show_all_predictions=False):\n",
        "    print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "    # Put model in evaluation mode\n",
        "    model_test.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    predictions , true_labels, input_sents = [], [], []\n",
        "\n",
        "    # Predict \n",
        "    for batch in prediction_dataloader:\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        decoded_inputs = [tokenizer.decode(b_input_ids[i]).strip(\"[CLS] \").strip( \"[SEP] \").strip(\" [PAD] \").strip(\"[PAD]\").strip(\" [SE\") for i in range(len(b_input_ids))]\n",
        "        # Telling the model not to compute or store gradients, saving memory and \n",
        "        # speeding up prediction\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            outputs = model_test(b_input_ids, token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        input_sents.extend(decoded_inputs)\n",
        "        \n",
        "        # Store predictions and true labels\n",
        "        predictions.extend(np.argmax(logits, axis=1))\n",
        "        true_labels.extend(label_ids)\n",
        "    correct = [0,0,0]\n",
        "    totals = [0, 0, 0]\n",
        "    for true_label, prediction in zip(true_labels, predictions):\n",
        "        if true_label == prediction:\n",
        "            correct[true_label] += 1\n",
        "        totals[true_label] += 1\n",
        "    print(\"Number of expressions with negative result\", true_labels.count(0), \"\\n\",  correct[0],  \" predicted correctly\",  \", accuracy \", correct[0]/totals[0] , \"\\n\")\n",
        "    print(\"Number of expressions with 0 result\", true_labels.count(1), \"\\n\",  correct[1], \" predicted correctly\", \", accuracy \", correct[1]/totals[1], \"\\n\")\n",
        "    print(\"Number of expressions with positive result\", true_labels.count(2),\"\\n\",  correct[2], \" predicted correctly\",\", accuracy \", correct[2]/totals[2], \"\\n\")\n",
        "    if show_all_predictions:\n",
        "        index_to_sentiment_map = {0:\"negative\", 1:\"zero\", 2:\"positive\"}\n",
        "        for sent in [sent + \"--> \"+index_to_sentiment_map[index]  for sent, index in zip(input_sents, predictions)]:\n",
        "            print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPr4f5hvzAwH",
        "colab_type": "code",
        "outputId": "377dc891-a275-4442-9eb7-2e2b13ccbbe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "eval_testdata(model_freeze_bert, show_all_predictions=False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 160 test sentences...\n",
            "Number of expressions with negative result 47 \n",
            " 0  predicted correctly , accuracy  0.0 \n",
            "\n",
            "Number of expressions with 0 result 2 \n",
            " 0  predicted correctly , accuracy  0.0 \n",
            "\n",
            "Number of expressions with positive result 111 \n",
            " 111  predicted correctly , accuracy  1.0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH-oKTjNrYB8",
        "colab_type": "code",
        "outputId": "33867e7a-aade-4dce-cb52-f8cbdc3818d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "eval_testdata(model_finetune_bert, show_all_predictions=False)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 160 test sentences...\n",
            "Number of expressions with negative result 47 \n",
            " 47  predicted correctly , accuracy  1.0 \n",
            "\n",
            "Number of expressions with 0 result 2 \n",
            " 0  predicted correctly , accuracy  0.0 \n",
            "\n",
            "Number of expressions with positive result 111 \n",
            " 108  predicted correctly , accuracy  0.972972972972973 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik",
        "colab_type": "text"
      },
      "source": [
        "## Question3 [1pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tezCqLQsB1BJ",
        "colab_type": "text"
      },
      "source": [
        "Try a few unseen examples of arithmetic questions using either model\\_freeze\\_bert or model\\_finetune\\_bert model, and find 10 interesting results.  We will give full marks as long as you provide some comments for why you chose some of the examples. The interesting results can, for example, be both successful extrapolation/interpolation results or surprising failure cases.  You can find some examples in our notebook.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJHaMPJk1AG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_sentiment_map = {0:\"negative\", 1:\"zero\", 2:\"positive\"}\n",
        "model = model_finetune_bert\n",
        "def what_is(arithmetic_input):\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        arithmetic_input, \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                )\n",
        "    input_sent = [arithmetic_input]\n",
        "    input_ids = [encoded_sent]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                            dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask) \n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(torch.tensor(input_ids), token_type_ids=None, \n",
        "                            attention_mask=torch.tensor(attention_masks))\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        print(index_to_sentiment_map[np.argmax(logits, axis=1)[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00mQOKMguI80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I-sf_VlOFTQ",
        "colab_type": "code",
        "outputId": "2be52c4e-bdb5-4d71-b56d-5def1a601d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"twelve minus fourteen\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-EyrQtKSJ2W",
        "colab_type": "code",
        "outputId": "bf064f9e-8359-4464-ab78-0f6aecec299c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"twelve plus fourteen\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5bJMb_NU9Aw",
        "colab_type": "code",
        "outputId": "53913bb6-7ef9-40dc-b3dd-2bc2cb069ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"eight plus thousand\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkDbHDVhsaMp",
        "colab_type": "code",
        "outputId": "0187462e-4c08-4ee4-cd81-a61ecf342f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"eight minus thousand\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u5YxpjcseDI",
        "colab_type": "code",
        "outputId": "9a32d9b8-f1bc-4e86-ff52-6609fa8ca165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"thousand minus eight\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPckLBdOshTJ",
        "colab_type": "code",
        "outputId": "efbc683c-5552-42e2-ddbd-2b562588df06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"eight minus thousand\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1e2e42d5-8ce7-4e47-dec8-26a7d4ff5811",
        "id": "6a04x0nNWbO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"1 minus 14\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJttWunQWdA0",
        "colab_type": "code",
        "outputId": "7bba7b71-ead5-4d88-ffe0-21374b99bdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"1 minus two\") # interesting."
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4a3KcjuWpmE",
        "colab_type": "code",
        "outputId": "e2f35be2-1e22-4c3b-af49-8a43e2e591e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus two\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLoFyJXPWtrV",
        "colab_type": "code",
        "outputId": "a0ba9cb0-f91b-4e58-fb6a-ec01495da2a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"three minus two minus eight\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NvEUBJWx6_",
        "colab_type": "code",
        "outputId": "ac7ec0b2-caa7-4c26-ec9d-d89f72533c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"three minus two\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKm-u-uwW3Rd",
        "colab_type": "code",
        "outputId": "b13d5990-22ed-48d6-a71f-265c0a40e719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus one minus one\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5q21x4YXA6k",
        "colab_type": "code",
        "outputId": "3f0a8f4d-e46b-45a9-a00c-95602bcdd955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus one minus one plus ten\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pImh34FXJzu",
        "colab_type": "code",
        "outputId": "2eff356a-e08f-4b53-f5ae-acfeae2711e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus one plus ten minus one\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGbzrdKTXfVK",
        "colab_type": "code",
        "outputId": "8a1d0ac0-52ac-48b3-90c1-2dad5dfb6c06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"minus three plus eight\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK2pH9if1RfA",
        "colab_type": "text"
      },
      "source": [
        "### My Try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEigPswd00qc",
        "colab_type": "code",
        "outputId": "d52b737c-700a-45be-80b8-6886832f174c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus 1\") # interesting"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWRCrTwP1u3D",
        "colab_type": "code",
        "outputId": "df6dca3c-894b-4183-8207-3923996be405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "what_is(\"one minus one\") # never produce 'zero'"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yhkjxrkNCBF4"
      },
      "source": [
        "## Question4 [1pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4_r_DAtCEJM",
        "colab_type": "text"
      },
      "source": [
        "This is an open question, and we will give marks as long as you show an attempt to try one of the following tasks.   \n",
        "1. Try data augmentation tricks to improve the performances for certain target labels that models were failing to predict.  \n",
        "2. Make a t-sne or PCA plot to visualize the embedding vectors of word tokens related to arithmetic expressions. \n",
        "3. Try different hyperparameter tunings. E.g. learning rates, optimizer, architecture of the classifier, training epochs, and batch size.  \n",
        "4. Evaluate the Multi-class Matthews correlation score for our imbalanced test dataset.  \n",
        "5. Run a baseline model using MLP without pre-trained BERT. You can assume the sequence length of all the data is 3 in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEYRYi-g-WZj",
        "colab_type": "text"
      },
      "source": [
        "## Try different hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jDpYixx7u-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_finetune_bert_new = BertCSC413_MLP.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 3,    \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hUFN-SLzXtg",
        "colab_type": "code",
        "outputId": "666f883a-49d8-4b96-c951-acc150ef34a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "finttune_bert_loss_vals_new = train_model(model_finetune_bert_new, lr=3e-5, epochs=10)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.74\n",
            "  Training epcoh took: 0:01:27\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Training epcoh took: 0:01:27\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:01:28\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:01:28\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:01:27\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:01:28\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:28\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:28\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:01:28\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:01:28\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApLEXunc_5RJ",
        "colab_type": "code",
        "outputId": "26dde486-5e8a-4f6a-d3d3-79554dbd99a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "eval_testdata(model_finetune_bert_new, show_all_predictions=False)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 160 test sentences...\n",
            "Number of expressions with negative result 47 \n",
            " 47  predicted correctly , accuracy  1.0 \n",
            "\n",
            "Number of expressions with 0 result 2 \n",
            " 0  predicted correctly , accuracy  0.0 \n",
            "\n",
            "Number of expressions with positive result 111 \n",
            " 111  predicted correctly , accuracy  1.0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WQn1Ty7KX12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}