\BOOKMARK [1][-]{section.1}{Optimization}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Stochastic Gradient Descent \(SGD\)}{section.1}% 2
\BOOKMARK [3][-]{subsubsection.1.1.1}{Minimum Norm Solution}{subsection.1.1}% 3
\BOOKMARK [3][-]{subsubsection.1.1.2}{Mini-batch SGD \(Optional\)}{subsection.1.1}% 4
\BOOKMARK [1][-]{section.2}{Gradient-Based Hyper-Parameter Optimization}{}% 5
\BOOKMARK [2][-]{subsection.2.1}{Computation Graph of Learning Rates}{section.2}% 6
\BOOKMARK [3][-]{subsubsection.2.1.1}{}{subsection.2.1}% 7
\BOOKMARK [3][-]{subsubsection.2.1.2}{}{subsection.2.1}% 8
\BOOKMARK [3][-]{subsubsection.2.1.3}{}{subsection.2.1}% 9
\BOOKMARK [2][-]{subsection.2.2}{Learning Learning Rates}{section.2}% 10
\BOOKMARK [3][-]{subsubsection.2.2.1}{}{subsection.2.2}% 11
\BOOKMARK [3][-]{subsubsection.2.2.2}{}{subsection.2.2}% 12
\BOOKMARK [3][-]{subsubsection.2.2.3}{}{subsection.2.2}% 13
\BOOKMARK [1][-]{section.3}{Convolutional Neutral Networks}{}% 14
\BOOKMARK [2][-]{subsection.3.1}{Convolutional Filters}{section.3}% 15
\BOOKMARK [2][-]{subsection.3.2}{Size of ConvNets}{section.3}% 16
