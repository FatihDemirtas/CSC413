\BOOKMARK [1][-]{section.1}{Weight Decay}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Under-parameterized Model [0pt]}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Over-parameterized Model}{section.1}% 3
\BOOKMARK [3][-]{subsubsection.1.2.1}{Warmup: Visualizing Weight Decay [1pt]}{subsection.1.2}% 4
\BOOKMARK [3][-]{subsubsection.1.2.2}{Gradient Descent and Weight Decay [0pt]}{subsection.1.2}% 5
\BOOKMARK [2][-]{subsection.1.3}{Adaptive optimizer and Weight Decay [1pt]}{section.1}% 6
\BOOKMARK [1][-]{section.2}{Ensembles and Bias-variance Decomposition}{}% 7
\BOOKMARK [2][-]{subsection.2.1}{Weight Average or Prediction Average?}{section.2}% 8
\BOOKMARK [3][-]{subsubsection.2.1.1}{[1pt]}{subsection.2.1}% 9
\BOOKMARK [1][-]{section.3}{Generalization and Dropout}{}% 10
\BOOKMARK [2][-]{subsection.3.1}{Regression Coefficients}{section.3}% 11
\BOOKMARK [3][-]{subsubsection.3.1.1}{Regression from X1 [0pt]}{subsection.3.1}% 12
\BOOKMARK [3][-]{subsubsection.3.1.2}{Regression from X2 [1pt]}{subsection.3.1}% 13
\BOOKMARK [3][-]{subsubsection.3.1.3}{Regression from \(X1, X2\) [1pt]}{subsection.3.1}% 14
\BOOKMARK [1][-]{section.4}{Hard-Coding Recurrent Neural Networks [1pt]}{}% 15
